# -*- coding: utf-8 -*-
"""Copy of combined CVNLP Assignment1_airin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q2EekfKEF1pOpfQYF6WopOfTXGMa_3Wy

**CVNLP Assignment - Garbage Classification**


---

Line wrapping for viewing purposes only
"""

from IPython.display import HTML, display

def set_css():
  display(HTML('''
  <style>
    pre {
        white-space: pre-wrap;
    }
  </style>
  '''))
get_ipython().events.register('pre_run_cell', set_css)

"""## **Importing Essential Libraries**"""

import os
from google.colab import files
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.metrics import confusion_matrix, classification_report

from IPython.display import display

"""## **Loading Dataset**

### Option 1: Loading and extracting manually from zip file
"""

# This is for uploading our datasets zip file
uploaded = files.upload()

# The below codes are directories for getting our zip files stored into colab
zip_path = '/content/garbage_classification.zip'  # Path to the uploaded zip file
extract_path = '/content/gdrive/MyDrive/garbage_classification'  # Where you want to extract the files

# Extract the zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Set the data directory path for further processing
data_dir = extract_path

print(f"Data directory: {data_dir}")

"""### Option 2: Loading from Google Drive

Mounting notebook to Google Drive
"""

import io
import requests
from google.colab import drive

drive.mount('/content/gdrive',force_remount=True)

data_dir = "/content/gdrive/MyDrive/garbage_classification"

# This is to check whether we extracted our dataset successfully
if os.path.exists(data_dir):
    print("Directory exists!")
    print("Contents:", os.listdir(data_dir))
else:
    print("Directory does not exist. Check the path.")

# Load data paths and identiy the number of classes in the dataset
data_dir = '/content/gdrive/MyDrive/garbage_classification/garbage_classification'
classes = os.listdir(data_dir)
print(f'classes found : [{classes}]')
data = []

for label in classes:
    folder_path = os.path.join(data_dir, label)
    for img_file in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_file)
        data.append([img_path, label])

# Convert to DataFrame
image_df = pd.DataFrame(data, columns=['image_path', 'label'])

# This is simply go-through for the content of our dataset
for root, dirs, files in os.walk(data_dir):
    print(f"Root: {root}")
    print(f"Directories: {dirs}")
    print(f"Files: {files}")
    print("----------")

print(data_dir)

"""### View sample dataset images"""

# Load and resize sample images
def load_image(path, size=(128, 128)):
    img = Image.open(path)
    img = img.resize(size)
    return np.array(img)

# Show some sample images
for label in classes:
    plt.figure(figsize=(13,5))
    plt.suptitle(f'\n Below are sample images for {label}:')
    sample_images = image_df[image_df['label'] == label]['image_path'].sample(5)
    for i, img_path in enumerate(sample_images):
        plt.subplot(1, 5, i+1)
        img = load_image(img_path)
        plt.imshow(img)
        plt.axis('off')
    plt.show()

"""## **Data Preprocessing and Explorative Data Analysis (EDA)**

### Removing any missing data
"""

# Remove for any missing values in the dataframe

image_df.dropna(subset=['image_path'], inplace=True)
print(image_df.isnull().sum())

"""### Barchart for class distribution"""

# plot barchart of image class distribution
plt.figure(figsize=(12, 5))
sns.countplot(x='label', data=image_df, color= 'orange')
plt.title('Class Distribution Bar Chart')
plt.bar_label(plt.gca().containers[0])
plt.xlabel('Classes')
plt.ylabel('Count')
plt.show()

"""### Pie chart for class distribution"""

# plot pie chart of image class distribution
class_counts = image_df['label'].value_counts()
plt.figure(figsize=(8, 8))
class_counts.plot.pie(cmap='tab10', autopct='%1.1f%%',legend=False)
plt.title('Class Distribution Pie Chart', fontsize=14)
plt.ylabel('')
plt.tight_layout()
plt.show()

"""# **Data Splitting**

Split the dataframe into Training, Validation, and Testing dataframes
"""

# Shuffle the dataset
image_df = shuffle(image_df, random_state=42)

# Split into train, validation, and test sets
train_data, temp_data = train_test_split(image_df, test_size=0.3, random_state=42)
val_data, test_data = train_test_split(temp_data, test_size=0.33, random_state=42)  # 10% test, 20% val

# Check splits
print(f"Training set size: {len(train_data)}")
print(f"Validation set size: {len(val_data)}")
print(f"Test set size: {len(test_data)}")

"""# **Data Augmentation**"""

# This is Data Augmentation
# improve model generalization by creating variations of existing images)
# creates variations (e.g., rotated, flipped, or zoomed versions)of images
# during each batch but doesn't permanently increase the dataset size.

# Augmnent training data with rotation, zooming, flipping, etc.
train_datagen = ImageDataGenerator(
    rescale=1./255,                # Normalize pixel values
    rotation_range=20,             # Rotate images by up to 20 degrees
    zoom_range=0.15,                # Randomly zoom in
    horizontal_flip=True,          # Flip images horizontally
    fill_mode='nearest'            # Fill empty pixels with nearest values
)

# No augmentation for validation and test data, only rescaling
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Create Generators for train, test, val dataframes
print("Training set:")
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_data,
    x_col='image_path',
    y_col='label',
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)
print("\nValidation set:")
val_generator = val_test_datagen.flow_from_dataframe(
    dataframe=val_data,
    x_col='image_path',
    y_col='label',
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)
print("\nTesting set:")
test_generator = val_test_datagen.flow_from_dataframe(
    dataframe=test_data,
    x_col='image_path',
    y_col='label',
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # Important for evaluation
)

#REFERENCE: Aenori/ECE_public (suggested by colab)
# -----------------------------------------------------------------------------

#show sample augmented images from the training dataset (trainData)
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 7, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
    plt.tight_layout()
    plt.show()

#show random training images
sample_training_images, _ = next(train_generator)
random_indices = np.random.choice(sample_training_images.shape[0], size=10, replace=False)
random_images = sample_training_images[random_indices]
plotImages(random_images)

"""# **Model Architecture Designing and Implementation**

## Designing the model architecture
"""

# CNN layer architecture configurations:
# 3 convolutional layers, 3 max pooling layers,
# 1 globalaveragepooling layer, 1 dropout layer, 2 dense layers

model = Sequential([

    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    # removed flatten instead use GlobalAvgPooling
    GlobalAveragePooling2D(),
    # Automatically adjusts the size(to  match the input size of dense layer)

    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(classes), activation='softmax')

])

model.summary()

"""## Visualise the model architecture"""

# plot the model layers
from tensorflow.keras.utils import plot_model

plot_model(
    model,
    show_shapes=True,
    show_layer_names=True,
    to_file='model_architecture.png',
    dpi=72  #smaller size
)

!pip install visualkeras
import visualkeras
visualkeras.layered_view(model, spacing = 20, legend = True)

"""# **Model Training**

### Compile model
"""

#compile model
model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'])

"""## Fit model for training"""

#fit model for training

early_stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)

history = model.fit(
  train_generator,
  epochs=60,
  validation_data=val_generator,
  callbacks = early_stopping,
  verbose=1
)

"""# **Model Evaluation and Metrics**

### Plot model accuracy over epochs
"""

# plot the trend of epoch histories
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""### Plot model loss over epochs"""

# plot training loss
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label = 'val_loss')
plt.title('Model Loss')

"""## Model Prediction and Evaluation

### Model training, validation, and testing accuracies
"""

# evaluate overall model training accuracy
train_loss, train_accuracy = model.evaluate(train_generator)
train_accuracy = round(train_accuracy, 3)
print(f'Train Accuracy: {train_accuracy}')

# evaluate overall model validation accuracy
val_loss, val_accuracy = model.evaluate(val_generator)
val_accuracy = round(val_accuracy, 3)
print(f'Validation Accuracy: {val_accuracy}')

# evaluate overall model testing accuracy
test_true = test_generator.classes
test_pred = model.predict(test_generator)
test_pred_classes = np.argmax(test_pred, axis=1)
test_loss, test_accuracy = model.evaluate(test_generator)

test_accuracy = round(test_accuracy, 3)
print(f'Test Accuracy: {test_accuracy}')

"""### Classification Report"""

# classification report
target_names = list(test_generator.class_indices.keys())
print(classification_report(test_true, test_pred_classes, target_names=target_names))

"""### Confusion matrix"""

# confusion matrix
conf_m = confusion_matrix(test_true, test_pred_classes)
plt.figure(figsize=(10, 8))           #colourful!!!!
sns.heatmap(conf_m, annot=True, fmt='d', cmap='magma', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted label')
plt.ylabel('Actual label')
plt.title('Confusion Matrix\n')
plt.show()

#REFERENCE = https://scikit-learn.org/0.20/auto_examples/model_selection/plot_confusion_matrix.html
#REFERENCE = https://stackoverflow.com/questions/56084882/how-to-show-precision-in-a-confusion-matrix
#-------------------------------------------------------------------------------

#accuracy of each class (a.k.a. recall)
class_accuracy = (np.diag(conf_m) / np.sum(conf_m, axis=1))
for i, class_name in enumerate(target_names):
    print(f'Accuracy for {class_name} class: {class_accuracy[i]:.2%}')

#plot the bar chart for the accuracy of each class
plt.figure(figsize=(10, 6))
plt.bar(target_names, class_accuracy)
plt.bar_label(plt.gca().containers[0])
plt.xlabel('Classes')
plt.ylabel('Accuracy')
plt.title('Accuracy of Each Class')

"""### Model Prediction

A test to classify a sample image from dataset

Paperboard class
"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/Paperboard/cardboard891.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")

"""Plastic class"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/Plastic/plastic848.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")

"""Organic class"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/Organic/biological975.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")

"""Metal class"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/metal/metal766.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")

"""Paper class"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/Paper/paper1025.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")

"""Battery class"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/Battery/battery932.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")

"""Glass class"""

from PIL import Image
from IPython.display import display

image_path = "/content/gdrive/MyDrive/garbage_classification/garbage_classification/Glass/white-glass750.jpg"
img = Image.open(image_path).resize((64, 64))  # Resize to match model input size
img_array = np.array(img) / 255.0  # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

# Display the image
display(img)

# Make prediction
predictions = model.predict(img_array)

# Get the predicted class
predicted_class = np.argmax(predictions)

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Print the prediction
print(f"The predicted class is: {class_labels[predicted_class]}")